---
title: "First runs with CAMBIUM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{First runs with CAMBIUM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# CAMBIUM

The CAMBIUM model was originally coded up in Pascal by David Drew and published as:


::: {#publication style="bold"}
Drew, D. M., Downes, G. M., & Battaglia, M. (2010). CAMBIUM, a process-based model of daily xylem development in Eucalyptus. Journal of Theoretical Biology, 264(2), 395â€“406. https://doi.org/10.1016/j.jtbi.2010.02.013

:::

This is a translation of the original Pascal code that was used for the publication. It was stripped from its interface settings and its visualisations.


# Run Instructions for CAMBIUM

To run CAMBIUM, one needs three types of inputs:

-Forcing data
-Parameters
-Run instructions

These are briefly described here. Then, an example model is run shown the default parameter set and provided forcing data.

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

```{r setup}
devtools::load_all()
library(CAMBIUM)
```

# Forcing data useable with CAMBIUM

Currently CAMBIUM relies on detailed forcing input from the CABALA stand model.
The plan for the future is to make CAMBIUM more flexible with regards to what forcing data is necessary for it to run. 
Potentially there will be different levels of forcing input detail at which the model can be run:
1) standalone as a wood formation model only or
2) in need of auxiliary inputs from stand models (current implementation)

From a default (?) cabala output, CAMBIUM required the following headers:

- `logdate`
- `RunNumber`
- `SoilWater`
- `GPP`
- `NPP`
- `PreDawnWP`
- `GreenHt`
- `TreeHeight`
- `etacr`
- `etaf`
- `wf`
- `etas`
- `DBH_CABALA`
- `treeheight`
- `MinTemp`
- `MaxTemp`
- `Qa`
- `gs1`
- `gs2`
- `Rainfall`
- `SPH`
- `VPD`


#Parameters required for the model

```{r parameter_sets}

data(params)

# paramter table
knitr::kable(params, format = "markdown")

```


#Run instructions

An instruction file will be generated by David Drew that will the point where the user can turn on switches, and specify certain
values within the model.
We still need to decide more on whether some of these should be parameters, or set as instructions. The current list of objects passed into the model as _instructions_ , and the values used for the example run is as follows: 

```{r run_instructions}


data(runsettings)


knitr::kable(runsettings, format = "markdown")

```


# Model run

```{r model_run, eval=FALSE}

debug_print <- TRUE  # Set globally

# Use debug flag inside or before calling the function
if (debug_print) {
  cat("Starting CAMBIUM model with debugging on...\n")
}

run_CAMBIUM(
  filename_forcing = "./Forcing_Data_Parameters/CABALAOutputs.csv",
  filename_param = "./Forcing_Data_Parameters/XylemParameters.csv",
  run_settings = runsettings
)

if (debug_print) {
  cat("CAMBIUM model completed.\n")
}
# filename_param should be made so that it could be replaced with the data frame that can be loaded in from the package data as shown in one of the above chunks.


```


# Model output post-processing and visualisation

This part is to be expanded a lot in the future. Some example outputs are already shown below:

```{r post_processing, eval=FALSE}
if (debug_print) cat("Starting output processing...\n")

# Assuming model predictions are stored in a variable `Output` and observed values are in `observed_values`
# You may load `observed_values` here if it's in an external file, for example:
# observed_values <- read.csv("./Forcing_Data_Parameters/ObservedValues.csv")

# Create a table combining model predictions and observed values
if (exists("Output") && exists("observed_values")) {
  
  # Ensure that the lengths of the predictions and observed values match
  if (nrow(Output) == nrow(observed_values)) {
    
    # Combine the data
    combined_data <- cbind(Output, Observed = observed_values)
    
    # Export the combined data as a CSV for further analysis
    write.csv(combined_data, file = file.path(getwd(), "Combined_Model_Observed.csv"), row.names = FALSE)
    
    # Print a preview of the combined data
    knitr::kable(head(combined_data), format = "markdown")
    
    cat("Model predictions and observed values combined and saved to 'Combined_Model_Observed.csv'.\n")
    
  } else {
    cat("Warning: The number of rows in model predictions and observed values do not match.\n")
  }
  
} else {
  cat("Either 'Output' or 'observed_values' does not exist.\n")
}
```

# Output Table

```{r Output}
# Get the list of objects in the environment
object_names <- ls()

# Create an empty list to store the objects as columns
columns <- list()

# Find the maximum length of all objects that have more than one value
max_length <- max(sapply(object_names, function(x) {
  obj_len <- length(get(x))
  if (obj_len > 1) return(obj_len)
  return(0)  # Ignore objects with only one value
}))

# Loop through each object and store it as a column in the list
for (object_name in object_names) {
  obj <- get(object_name)  # Retrieve the object from the global environment
  
  # Ensure the object is of a compatible type (numeric, character, logical)
  if ((is.numeric(obj) || is.character(obj) || is.logical(obj)) && length(obj) > 1) {
    # Pad the object with NAs to make its length equal to max_length
    padded_obj <- c(obj, rep(NA, max_length - length(obj)))
    columns[[object_name]] <- padded_obj
  } else {
    cat("Skipping", object_name, "- not a compatible type (numeric/character/logical) or has only one value\n")
  }
}

# Convert the list to a data frame named 'Output'
if (length(columns) > 0) {
  Output <- as.data.frame(columns)
  
  # Define the output directories
  output_directory <- getwd()
  final_plots_directory <- file.path(output_directory, "Final_plots")
  
  # Create the Final_plots directory if it does not exist
  if (!dir.exists(final_plots_directory)) {
    dir.create(final_plots_directory)
  }
  
  # Export the data frame to a CSV file named 'Output_results.csv' in the current directory
  write.csv(Output, file = file.path(output_directory, "Output_results.csv"), row.names = FALSE)
  
  # Export the data frame to a CSV file named 'Output_results.csv' in the Final_plots directory
  write.csv(Output, file = file.path(final_plots_directory, "Output_results.csv"), row.names = FALSE)
  
  cat("All compatible objects exported as columns to 'Output_results.csv' in the current directory and 'Final_plots' directory\n")
} else {
  cat("No compatible objects with more than one value found\n")
}
```

```{run_settings_creation, eval=FALSE}


# Create a vector of instructions
instructions <- c("WaterStressShape <<- TRUE",
                  "AuxSens <<- TRUE",
                  "CumTempDuration <<- 15",
                  "RadialCellFiles_Position <<- 4",
                  "StartSizeVariation <<- TRUE",
                  "SegmentLengthFibres <<- 200",
                  "SegmentLengthVessels <<- 400",
                  "AuxinConcChangeMethod <<- 0",
                  "ThickeningDurationControl <<- 0",
                  "SecThickDur <<- FALSE",
                
                  "MinSizeSecThickSet <<- FALSE",
                  "GrowthPhaseMinSize <<- FALSE",
                  "CellIdentityDeterminationMethod <<- 'Barlow'",
                  "TempAcclimation <<- 20",
                  "SiteLat <<- -33",
                  "ThickRateEnvironment <<- TRUE",
                 
                  "InterCellAdjustment <<- TRUE",
                  "MaxIntCellAdjust <<-     8",
                  "XMCCrush <<- TRUE",
                  "VesselForm <<- TRUE")

# Create an empty dataframe
df <- data.frame(Instruction_Name = character(),
                 Instruction_Value = character(),
                 stringsAsFactors = FALSE)

# Process each instruction line
for (instruction in instructions) {
  # Split the line by "<<-"
  parts <- strsplit(instruction, "<<-")[[1]]
  
  # Trim leading and trailing whitespace
  parts <- trimws(parts)
  
  # Extract the instruction name and value
  instruction_name <- parts[1]
  instruction_value <- parts[2]
  
  # Remove any trailing comments
  instruction_value <- strsplit(instruction_value, "#")[[1]][1]
  
  # Append the instruction to the dataframe
  df <- rbind(df, data.frame(Instruction_Name = instruction_name,
                             Instruction_Value = instruction_value,
                             stringsAsFactors = FALSE))
  
  
  
}

 df[c(1,2,5,10:12,16,17,19,20),2] <- as.logical(df[c(1,2,5,10:12,16,17,19,20),2])
  df[c(3,4,6:9,14,15,18),2] <- as.numeric(df[c(3,4,6:9,14,15,18),2])
  df[13,2] <- as.character(df[13,2])
# Print the dataframe
df


```
